# -*- coding: utf-8 -*-
"""PracticaAprendizajeSupervisadoClasificiacion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZjfMEYGCWg19-RG3ZE6hilMUmH3YkF-D
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix,classification_report, accuracy_score,recall_score,precision_score,roc_auc_score,roc_curve,auc

splits = {'train': 'train.csv', 'validation': 'validation.csv', 'test': 'test.csv'}
df = pd.read_csv("hf://datasets/SaladSlayer00/ehr_nigeria_cancer/" + splits["train"])
df

df.drop('Unnamed: 0',axis=1,inplace=True)

df.head()

df.info()

df.isnull().sum()

moda = df['Treatment'][df['Treatment'].notna()].mode()[0]
moda

df['Treatment']= df['Treatment'].fillna(moda).astype('object')

df.isnull().sum()

df.duplicated().sum()

df.columns.duplicated().sum()

df_backup = df.copy()
df = df_backup

df['Date_of_incidence'] = pd.to_datetime(df['Date_of_incidence'])
df['Date_of_incidence'] = df['Date_of_incidence'].dt.year

df['Date_last_checked'] = pd.to_datetime(df['Date_last_checked'])
df['Date_last_checked'] = df['Date_last_checked'].dt.year

for col in df.columns:
  print(f'{col}: {df[col].unique()}')

df.drop('Diff',axis=1,inplace=True)

for col in df.select_dtypes(include=np.number).columns:
  plt.figure()
  sns.histplot(df[col],bins=10)
  plt.title(f"Histograma de {col}")
  plt.show()

for col in df.select_dtypes(include="object").columns[:]:
  plt.figure(figsize=(10,8))
  order = df[col].value_counts().index
  sns.countplot(x=col,data=df,order=order)
  plt.title(f"Counplot de {col}")
  plt.xlabel(col)
  plt.ylabel("Count")
  plt.xticks(rotation=45,ha='right')
  plt.show()

df.head()

plt.figure()
sns.countplot(data=df,x='Treatment',hue='Status',palette='muted')
plt.title("Distribucion de Status por tipo de Treatment")
plt.xlabel("Tipo de Treatment")
plt.ylabel("Cantidad de personas")
plt.xticks(rotation=45,ha='right')
plt.legend(title='Status',labels=['Alive','Dead','Unknown'])
plt.show()

x = df.loc[:,df.columns !='Status']
y = df.loc[:,'Status']
x

x = pd.get_dummies(x,drop_first=True)
selector = SelectKBest(chi2,k=10)
x_new = selector.fit_transform(x,y)
selected_features = x.columns[selector.get_support()]
print(selected_features)

df_filter = df[['Breast_quadrant','Morphology','Education','Diagnosis','Treatment','Status']].copy()
df_filter

df_filter.info()

for col in df_filter.columns:
  print(f'{col}: {df_filter[col].unique()}')

encoder_le = LabelEncoder()
df_filter['Breast_quadrant'] = encoder_le.fit_transform(df_filter['Breast_quadrant'])
print(df_filter['Breast_quadrant'].unique())
print(encoder_le.classes_)

df_filter['Morphology'] = encoder_le.fit_transform(df_filter['Morphology'])
print(df_filter['Morphology'].unique())
print(encoder_le.classes_)

df_filter['Education'] = encoder_le.fit_transform(df_filter['Education'])
print(df_filter['Education'].unique())
print(encoder_le.classes_)

df_filter['Diagnosis'] = encoder_le.fit_transform(df_filter['Diagnosis'])
print(df_filter['Diagnosis'].unique())
print(encoder_le.classes_)

df_filter['Treatment'] = encoder_le.fit_transform(df_filter['Treatment'])
print(df_filter['Treatment'].unique())
print(encoder_le.classes_)

df_filter['Status'] = encoder_le.fit_transform(df_filter['Status'])
print(df_filter['Status'].unique())
print(encoder_le.classes_)

df_filter

df_filter.info()

plt.pie(df_filter['Status'].value_counts(),labels=df_filter['Status'].value_counts().index,autopct="%1.1f%%")
plt.title("Distribucion de Status")
plt.show()

df['Status'].value_counts()

x = df_filter.iloc[:,:-1]
x

y = df_filter.loc[:,'Status']
y

x_train,x_test,y_train,y_test = train_test_split(x,y,train_size=0.8,random_state=52,stratify=y)

from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=52)
x_train_resampled,y_train_resampled = smote.fit_resample(x_train,y_train)

y_train_resampled.value_counts()

plt.pie(y_train_resampled.value_counts(),labels=y_train_resampled.value_counts().index,autopct="%1.1f%%")
plt.title("Distribucion de la variable target")
plt.show()

from sklearn.naive_bayes import GaussianNB,MultinomialNB
modeloBayes = GaussianNB()
modeloBayes.fit(x_train_resampled,y_train_resampled)

y_pred_nb = modeloBayes.predict(x_test)

print(classification_report(y_test,y_pred_nb))

modelo = LogisticRegression(random_state=52,max_iter=1000)
modelo.fit(x_train_resampled,y_train_resampled)

y_pred = modelo.predict(x_test)


predicciones = pd.DataFrame({'y_pred':y_pred, 'y_test':y_test})
predicciones

cm = confusion_matrix(y_test,y_pred_nb)
plt.figure()
sns.heatmap(cm,annot=True,fmt='d',cmap='Blues')
plt.title("Matriz de confusion")
plt.xlabel("Predicciones  - y_pred")
plt.ylabel("Valores reales - y_test")
plt.show()

print(classification_report(y_test,y_pred_nb))

accuracy = accuracy_score(y_test,y_pred_nb)
precision = precision_score(y_test,y_pred_nb,average="weighted")
recall = recall_score(y_test,y_pred_nb, average=None,labels=[0,1,2])

print(f"accuracy: {accuracy *100:.2f}%")
print(f"precision: {precision*100:.2f}%")
print(f"recall: {recall}")

TPR = []
for i in range(len(cm)):
    TP = cm[i, i]
    FN = sum(cm[i, :]) - cm[i, i]
    TPR.append(TP / (TP + FN))

print(f'Sensibilidad (Tasa Verdaderos positivos) por clase: {TPR}')

TNR = []
for i in range(len(cm)):
    TN = sum(sum(cm)) - (sum(cm[i, :]) + sum(cm[:, i]) - cm[i, i])
    FP = sum(cm[:, i]) - cm[i, i]
    TNR.append(TN / (TN + FP))

print(f'Especificidad (Tasa Verdaderos negativos) por clase: {TNR}')

from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier

y_test_bin = label_binarize(y_test,classes=[0,1,2])
num_Classes = y_test_bin.shape[1]
num_Classes

classifier = OneVsRestClassifier(modeloBayes)
y_score = classifier.fit(x_train_resampled,y_train_resampled).predict_proba(x_test)
y_score

fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(num_Classes):
  fpr[i],tpr[i], _ = roc_curve(y_test_bin[:,i], y_score[:,i])
  roc_auc[i] = auc(fpr[i],tpr[i])

plt.figure()
for i in range(num_Classes):
  plt.plot(fpr[i],tpr[i],label= f'Clase {i} (AUC = {roc_auc[i]:.2f})')

plt.plot([0,1],[0,1],'k--')
plt.xlim([0.0,1.0])
plt.ylim([0.0,1.05])
plt.title("Grafica ROC AUC Multiclases")
plt.xlabel("Tasa de falsos positivos (fpr)")
plt.ylabel("Tasa de verdaderos positivos (tpr)")
plt.legend(loc="lower right")
plt.show()

roc_auc_weighted = auc(fpr[0], tpr[0]) * sum(y_test_bin[:,0]) + auc(fpr[1], tpr[1]) * sum(y_test_bin[:,1]) + auc(fpr[2], tpr[2]) * sum(y_test_bin[:,2])
roc_auc_weighted /= sum(sum(y_test_bin))
print(f"AUC ponderado promedio: {roc_auc_weighted:.2f}")